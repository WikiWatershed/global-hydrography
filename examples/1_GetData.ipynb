{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Global Hydrography from NGA TDX-Hydro \n",
    "\n",
    "This notebook demonstrates how to use functions in the [WikiWatershed/global-hydrography](https://github.com/WikiWatershed/global-hydrography) package to fetch data files from the TDX-Hydro dataserts released by the [US National Geospatial-Intelligence Agency (NGA)](https://www.nga.mil).\n",
    "\n",
    "It uses processes that were explored in these notebooks:\n",
    "- `sandbox/explore_data_sources.ipynb`\n",
    "- `sandbox/reading_files.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Setup\n",
    "\n",
    "Carefully follow our **[Installation Instructions](README.md#get-started)**, especially including:\n",
    "- Creating a virtual environment for this repository (step 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Imports\n",
    "Using common conventions and following the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html): \n",
    "- https://google.github.io/styleguide/pyguide.html#s2.2-imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "import fsspec\n",
    "# import s3fs\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyogrio\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hydrography'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm conda environment\n",
    "os.environ['CONDA_DEFAULT_ENV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for Global Hydrography\n",
    "import global_hydrography as gh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you get `ModuleNotFoundError`:\n",
    "\n",
    "Then follow Installation instructions Step **4. Add your `global_hydrography` Path to Miniconda/Anaconda sites-packages** in the main ReadMe, running the following in your console, replacing `/your/path/to/global_hydrography/src` with your specific path.\n",
    "\n",
    "```console\n",
    "conda develop '/your/path/to/global_hydrography/src'\n",
    "```\n",
    "\n",
    "Then restart the kernel and rerun the imports above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path exists, skipping /Users/aaufdenkampe/Documents/Python/global-hydrography/src\n",
      "completed operation for: /Users/aaufdenkampe/Documents/Python/global-hydrography/src\n"
     ]
    }
   ],
   "source": [
    "! conda develop '/Users/aaufdenkampe/Documents/Python/global-hydrography/src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'delineation',\n",
       " 'io',\n",
       " 'mnsi',\n",
       " 'preprocess',\n",
       " 'process']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the namespace for global-hydrography modules, functions, etc.\n",
    "dir(gh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths for Data Inputs/Outputs\n",
    "Use the [`pathlib`](https://docs.python.org/3/library/pathlib.html) library, whose many benfits for managing paths over  `os` library or string-based approaches are described in [this blog post](https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f).\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) user guide: https://realpython.com/python-pathlib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm your current working directory (cwd) and repo/project directory\n",
    "working_dir = Path.cwd()\n",
    "project_dir = working_dir.parent\n",
    "# make a temporary data directory that we .gitignore\n",
    "data_dir = project_dir / 'data_temp'\n",
    "data_dir.mkdir(parents=True, exist_ok=True) # Required if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create local file system using `fsspec` library\n",
    "\n",
    "We'll use the Filesystem Spec ([`fsspec`](https://filesystem-spec.readthedocs.io)) library and its extensions throughout this project to provide a unified pythonic interface to local, remote and embedded file systems and bytes storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local file system using fsspec library\n",
    "# local_fs = fsspec.implementations.local.LocalFileSystem()\n",
    "local_fs = fsspec.filesystem('local') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/global_hydrography.qgz',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/geoglows-v2',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/.DS_Store',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_downcast_gdf.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_gdf.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_pa_gdf.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_ga_pa_df.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_gpd_gdf.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_pa_geo_df.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/io_10m_annual_lulc',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/nhdplus2',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/hydrobasins',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_gpd_gdf.gpkg',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/nga',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_pa_df.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_downscaled_gdf.parquet',\n",
       " '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/test_df.parquet']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List files in our temporary data directory\n",
    "local_fs.ls(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/global_hydrography.qgz',\n",
       " 'size': 136499,\n",
       " 'type': 'file',\n",
       " 'created': 1721235118.8378024,\n",
       " 'islink': False,\n",
       " 'mode': 33188,\n",
       " 'uid': 502,\n",
       " 'gid': 20,\n",
       " 'mtime': 1721235118.8372164,\n",
       " 'ino': 301838904,\n",
       " 'nlink': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List file details (equivalent to file info)\n",
    "local_data_list = local_fs.ls(data_dir, detail=True)\n",
    "# Show first item's details\n",
    "local_data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGA TDX-Hydro\n",
    "\n",
    "Data downloadable from the National Geospatial-Intelligence Agency (NGA) Office for Geomatics website, https://earth-info.nga.mil/, under the \"Geosciences\" tab.\n",
    "\n",
    "The [TDX-Hydro Technical Document](https://earth-info.nga.mil/php/download.php?file=tdx-hydro-technical-doc) provides detailed information on how the datasets were developed and validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/nga')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create local data directory\n",
    "tdx_dir = data_dir / 'nga'\n",
    "tdx_dir.mkdir(parents=True, exist_ok=True)\n",
    "tdx_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fs.exists(tdx_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TDX-Hydro Metadata\n",
    "\n",
    "TDX-Hydro datasets are organized into 62 continental sub-units using the same 10-digit Level 2 codes (HYBAS_ID) developed by [HydroSHEDS v1 HydroBASINS](https://www.hydrosheds.org/products/hydrobasins). More information on the semantics of these codes are provided in the [HydroBASINS Technical Documentation](https://data.hydrosheds.org/file/technical-documentation/HydroBASINS_TechDoc_v1c.pdf).\n",
    "\n",
    "NGA’s TDX-Hydro v1 files are organized by:\n",
    "- TDXHydroRegion = HYBAS_ID Level 2 codes \n",
    "- Download: https://earth-info.nga.mil/php/download.php?file=hydrobasins_level2\n",
    "- 62 globally\n",
    "- Crosswalk from TDXHydroRegion to PFAF_ID values are provided in HydroBASINS Level 2 files (see above), such as https://data.hydrosheds.org/file/HydroBASINS/standard/hybas_af_lev02_v1c.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames and local paths\n",
    "tdx_hydroregions_filename = Path('hydrobasins_level2.geojson')\n",
    "tdx_hydroregions_filepath = tdx_dir / tdx_hydroregions_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://earth-info.nga.mil/php/download.php?file=hydrobasins_level2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdx_root_url = 'https://earth-info.nga.mil/php/download.php'\n",
    "\n",
    "# Download URL for Basin GeoJSON File with ID Numbers\n",
    "tdx_hydroregions_url = f'{tdx_root_url}?file={tdx_hydroregions_filename.stem}'\n",
    "tdx_hydroregions_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file system for TDX-Hydro HTTP filesystem, which unfortunately \n",
    "# isn't set up in accessible directories so files need to be accessed one at a time.\n",
    "tdx_fs = fsspec.filesystem(protocol='http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'https://earth-info.nga.mil/php/download.php?file=hydrobasins_level2',\n",
       " 'size': 95389402,\n",
       " 'mimetype': 'application/octet-stream',\n",
       " 'url': 'https://earth-info.nga.mil/php/download.php?file=hydrobasins_level2',\n",
       " 'type': 'file'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get info on the file, which should only take a few seconds\n",
    "tdx_fs.info(tdx_hydroregions_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have it!\n",
      "CPU times: user 196 µs, sys: 81 µs, total: 277 µs\n",
      "Wall time: 260 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the remote file and save to local directory, returns None\n",
    "if not tdx_hydroregions_filepath.exists:\n",
    "    tdx_fs.get(tdx_hydroregions_url, str(tdx_hydroregions_filepath))\n",
    "else:\n",
    "    print('We have it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '/Users/aaufdenkampe/Documents/Python/global-hydrography/data_temp/nga/hydrobasins_level2.geojson',\n",
       " 'size': 95389402,\n",
       " 'type': 'file',\n",
       " 'created': 1721407912.568478,\n",
       " 'islink': False,\n",
       " 'mode': 33188,\n",
       " 'uid': 502,\n",
       " 'gid': 20,\n",
       " 'mtime': 1715117902.7792468,\n",
       " 'ino': 267369098,\n",
       " 'nlink': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm info of local file matches remote file\n",
    "local_fs.info(tdx_hydroregions_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 62 entries, 0 to 61\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   HYBAS_ID  62 non-null     int64   \n",
      " 1   SUB_AREA  62 non-null     float64 \n",
      " 2   geometry  62 non-null     geometry\n",
      "dtypes: float64(1), geometry(1), int64(1)\n",
      "memory usage: 1.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HYBAS_ID</th>\n",
       "      <th>SUB_AREA</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020000010</td>\n",
       "      <td>3258330.6</td>\n",
       "      <td>MULTIPOLYGON (((38.1995 18.24379, 38.19861 18....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020011530</td>\n",
       "      <td>4660080.9</td>\n",
       "      <td>MULTIPOLYGON (((19.42136 -34.68525, 19.4203 -3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020018110</td>\n",
       "      <td>4900405.1</td>\n",
       "      <td>MULTIPOLYGON (((9.15742 -2.07022, 9.16221 -2.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020021940</td>\n",
       "      <td>4046600.5</td>\n",
       "      <td>MULTIPOLYGON (((-16.1354 11.25485, -16.12926 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020027430</td>\n",
       "      <td>6923559.6</td>\n",
       "      <td>MULTIPOLYGON (((-16.48427 19.64912, -16.48272 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3020003790</td>\n",
       "      <td>2620366.5</td>\n",
       "      <td>MULTIPOLYGON (((76.9259 72.15787, 76.925 72.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3020005240</td>\n",
       "      <td>1173702.8</td>\n",
       "      <td>MULTIPOLYGON (((84.71574 73.8423, 84.69252 73....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3020008670</td>\n",
       "      <td>2487156.5</td>\n",
       "      <td>MULTIPOLYGON (((125.90113 73.46736, 125.98238 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3020009320</td>\n",
       "      <td>2722031.4</td>\n",
       "      <td>MULTIPOLYGON (((138.39167 56.69923, 138.39028 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3020024310</td>\n",
       "      <td>302583.2</td>\n",
       "      <td>MULTIPOLYGON (((97.95833 46.95417, 97.95869 46...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HYBAS_ID   SUB_AREA                                           geometry\n",
       "0   1020000010  3258330.6  MULTIPOLYGON (((38.1995 18.24379, 38.19861 18....\n",
       "1   1020011530  4660080.9  MULTIPOLYGON (((19.42136 -34.68525, 19.4203 -3...\n",
       "2   1020018110  4900405.1  MULTIPOLYGON (((9.15742 -2.07022, 9.16221 -2.0...\n",
       "3   1020021940  4046600.5  MULTIPOLYGON (((-16.1354 11.25485, -16.12926 1...\n",
       "4   1020027430  6923559.6  MULTIPOLYGON (((-16.48427 19.64912, -16.48272 ...\n",
       "..         ...        ...                                                ...\n",
       "57  3020003790  2620366.5  MULTIPOLYGON (((76.9259 72.15787, 76.925 72.16...\n",
       "58  3020005240  1173702.8  MULTIPOLYGON (((84.71574 73.8423, 84.69252 73....\n",
       "59  3020008670  2487156.5  MULTIPOLYGON (((125.90113 73.46736, 125.98238 ...\n",
       "60  3020009320  2722031.4  MULTIPOLYGON (((138.39167 56.69923, 138.39028 ...\n",
       "61  3020024310   302583.2  MULTIPOLYGON (((97.95833 46.95417, 97.95869 46...\n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdx_hydroregions_gdf = gpd.read_file(tdx_hydroregions_filepath)\n",
    "tdx_hydroregions_gdf.info()\n",
    "tdx_hydroregions_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get TDXHydro Regions from HydroBASINS\n",
    "\n",
    "This can give us extra metadata and names for guiding the ModelMW user.\n",
    "\n",
    "The main purpose of fetching HydroBASINS v1c data is to understand the spatial organization of TDX-Hydro datafiles, which are organized around HydroBASINS Level 2 Continental Subunits.\n",
    "\n",
    "Get and visualize HydroBASINS Level 2 Continental Subunits.\n",
    "- https://www.hydrosheds.org/products/hydrobasins\n",
    "\n",
    "Data are downloadable by continent at different levels, such as `Africa Level 02 - Standard (2MB)` is downloaded via:\n",
    "- https://data.hydrosheds.org/file/HydroBASINS/standard/hybas_af_lev02_v1c.zip\n",
    "\n",
    "Refer to [HydroBASINS Technical Documentation](https://data.hydrosheds.org/file/technical-documentation/HydroBASINS_TechDoc_v1c.pdf) for attribute descriptions and coding and naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HydroBASINS Identifier & Region (Section 3.1 in Tech Docs)\n",
    "# 2-character identifier used for file naming\n",
    "hybas_region_dict = {\n",
    "    'af': 'Africa',\n",
    "    'ar': 'North American Arctic',\n",
    "    'as': 'Central and South-East Asia',\n",
    "    'au': 'Australia and Oceania',\n",
    "    'eu': 'Europe and Middle East',\n",
    "    'gr': 'Greenland',\n",
    "    'na': 'North America and Caribbean',\n",
    "    'sa': 'South America',\n",
    "    'si': 'Siberia',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HydroBASINS Region Numbers (Section 3.1 in Tech Docs)\n",
    "# Single digit prefix for HYBAS_ID values at all levels\n",
    "hybas_region_number_dict = {\n",
    "    1: 'Africa',\n",
    "    2: 'Europe and Middle East',\n",
    "    3: 'Siberia',\n",
    "    4: 'Central and South-East Asia',\n",
    "    5: 'Australia and Oceania',\n",
    "    6: 'South America',\n",
    "    7: 'North America and Caribbean',\n",
    "    8: 'North American Arctic',\n",
    "    9: 'Greenland',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct URL patterns\n",
    "hybas_root_url = 'https://data.hydrosheds.org/file/HydroBASINS'\n",
    "hybas_format = 'standard'\n",
    "hybas_url = f'{hybas_root_url}/{hybas_format}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local directory path\n",
    "hybas_dir = data_dir / 'hydrobasins'\n",
    "hybas_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create remote filesytem\n",
    "# HydroBASINS files need to be accessed one file at a time\n",
    "hybas_fs = fsspec.filesystem(protocol='http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybas_files(\n",
    "    remote_filesystem: fsspec.filesystem,\n",
    "    local_dir: Path,\n",
    "    hybas_region_dict: dict,\n",
    "    level: str = '02',\n",
    ")-> None:\n",
    "\n",
    "    for region in hybas_region_dict.keys():\n",
    "        hybas_filename = f'hybas_{region}_lev{level}_v1c.zip'\n",
    "        hybas_filepath = f'{hybas_url}/{hybas_filename}'\n",
    "        if (local_dir / hybas_filename).exists():\n",
    "            print(hybas_filename, 'We have it!')\n",
    "        else:\n",
    "            # Get the remote file and save to local directory, returns None\n",
    "            hybas_fs.get(hybas_filepath, local_dir)\n",
    "            print(hybas_filename, 'Dowloaded!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybas_af_lev02_v1c.zip We have it!\n",
      "hybas_ar_lev02_v1c.zip We have it!\n",
      "hybas_as_lev02_v1c.zip We have it!\n",
      "hybas_au_lev02_v1c.zip We have it!\n",
      "hybas_eu_lev02_v1c.zip We have it!\n",
      "hybas_gr_lev02_v1c.zip We have it!\n",
      "hybas_na_lev02_v1c.zip We have it!\n",
      "hybas_sa_lev02_v1c.zip We have it!\n",
      "hybas_si_lev02_v1c.zip We have it!\n"
     ]
    }
   ],
   "source": [
    "# Get files\n",
    "get_hybas_files(\n",
    "    hybas_fs,\n",
    "    hybas_dir,\n",
    "    hybas_region_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open all Level 2 files and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all continents (level 2).\n",
    "level = '02'\n",
    "for region in hybas_region_dict.keys():\n",
    "    hybas_filename = f'hybas_{region}_lev{level}_v1c.zip'\n",
    "    hybas_filepath = f'{hybas_url}/{hybas_filename}'\n",
    "    hybas_fs.get(hybas_filepath, hybas_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af Africa\n",
      "   [['hybas_af_lev02_v1c' 'Polygon']]\n",
      "   [11 12 13 14 15 17 18 16]\n",
      "ar North American Arctic\n",
      "   [['hybas_ar_lev02_v1c' 'Polygon']]\n",
      "   [81 82 83 35 84 85 86]\n",
      "as Central and South-East Asia\n",
      "   [['hybas_as_lev02_v1c' 'Polygon']]\n",
      "   [42 43 44 45 41 48 46 47 49]\n",
      "au Australia and Oceania\n",
      "   [['hybas_au_lev02_v1c' 'Polygon']]\n",
      "   [51 52 53 56 54 55 57]\n",
      "eu Europe and Middle East\n",
      "   [['hybas_eu_lev02_v1c' 'Polygon']]\n",
      "   [21 22 23 24 25 26 27 28 29]\n",
      "gr Greenland\n",
      "   [['hybas_gr_lev02_v1c' 'Polygon']]\n",
      "   [91]\n",
      "na North America and Caribbean\n",
      "   [['hybas_na_lev02_v1c' 'Polygon']]\n",
      "   [77 78 71 72 73 74 75 76]\n",
      "sa South America\n",
      "   [['hybas_sa_lev02_v1c' 'Polygon']]\n",
      "   [61 62 63 64 65 66 67]\n",
      "si Siberia\n",
      "   [['hybas_si_lev02_v1c' 'Polygon']]\n",
      "   [31 32 33 34 35 36]\n",
      "CPU times: user 615 ms, sys: 57.4 ms, total: 673 ms\n",
      "Wall time: 830 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create list of GeoDataframes of all continental regions\n",
    "# Insert 'REGION_NAME' as a new column\n",
    "level = '02'\n",
    "gdf_list = []\n",
    "for region_id, region_name in hybas_region_dict.items():\n",
    "    print(region_id, region_name)\n",
    "    hybas_filename = f'hybas_{region_id}_lev{level}_v1c.zip'\n",
    "    print('  ', pyogrio.list_layers(hybas_dir/hybas_filename))\n",
    "    gdf = gpd.read_file(\n",
    "        hybas_dir/hybas_filename, \n",
    "        engine='pyogrio',\n",
    "    )\n",
    "    gdf.insert(1, 'REGION_NAME', region_name)\n",
    "    print('  ', gdf.PFAF_ID.values)\n",
    "    gdf_list.append(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 62 entries, 0 to 61\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   HYBAS_ID     62 non-null     int64   \n",
      " 1   REGION_NAME  62 non-null     object  \n",
      " 2   NEXT_DOWN    62 non-null     int64   \n",
      " 3   NEXT_SINK    62 non-null     int64   \n",
      " 4   MAIN_BAS     62 non-null     int64   \n",
      " 5   DIST_SINK    62 non-null     float64 \n",
      " 6   DIST_MAIN    62 non-null     float64 \n",
      " 7   SUB_AREA     62 non-null     float64 \n",
      " 8   UP_AREA      62 non-null     float64 \n",
      " 9   PFAF_ID      62 non-null     int32   \n",
      " 10  ENDO         62 non-null     int32   \n",
      " 11  COAST        62 non-null     int32   \n",
      " 12  ORDER        62 non-null     int32   \n",
      " 13  SORT         62 non-null     int64   \n",
      " 14  geometry     62 non-null     geometry\n",
      "dtypes: float64(4), geometry(1), int32(4), int64(5), object(1)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.concat(gdf_list, ignore_index=True).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 62 entries, 0 to 61\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   HYBAS_ID     62 non-null     int64   \n",
      " 1   REGION_NAME  62 non-null     category\n",
      " 2   NEXT_DOWN    62 non-null     int64   \n",
      " 3   NEXT_SINK    62 non-null     int64   \n",
      " 4   MAIN_BAS     62 non-null     int64   \n",
      " 5   DIST_SINK    62 non-null     float64 \n",
      " 6   DIST_MAIN    62 non-null     float64 \n",
      " 7   SUB_AREA     62 non-null     float64 \n",
      " 8   UP_AREA      62 non-null     float64 \n",
      " 9   PFAF_ID      62 non-null     int32   \n",
      " 10  ENDO         62 non-null     int32   \n",
      " 11  COAST        62 non-null     int32   \n",
      " 12  ORDER        62 non-null     int32   \n",
      " 13  SORT         62 non-null     int64   \n",
      " 14  geometry     62 non-null     geometry\n",
      "dtypes: category(1), float64(4), geometry(1), int32(4), int64(5)\n",
      "memory usage: 6.4 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HYBAS_ID</th>\n",
       "      <th>REGION_NAME</th>\n",
       "      <th>NEXT_DOWN</th>\n",
       "      <th>NEXT_SINK</th>\n",
       "      <th>MAIN_BAS</th>\n",
       "      <th>DIST_SINK</th>\n",
       "      <th>DIST_MAIN</th>\n",
       "      <th>SUB_AREA</th>\n",
       "      <th>UP_AREA</th>\n",
       "      <th>PFAF_ID</th>\n",
       "      <th>ENDO</th>\n",
       "      <th>COAST</th>\n",
       "      <th>ORDER</th>\n",
       "      <th>SORT</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020000010</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>1020000010</td>\n",
       "      <td>1020000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3258330.6</td>\n",
       "      <td>3258330.6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((33.67778 27.62917, 33.67119 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020011530</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>1020011530</td>\n",
       "      <td>1020011530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4660080.9</td>\n",
       "      <td>4660080.9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTIPOLYGON (((34.80278 -19.81667, 34.79279 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020018110</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>1020018110</td>\n",
       "      <td>1020018110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4900405.1</td>\n",
       "      <td>4900405.1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((5.64444 -1.47083, 5.62972 -1.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020021940</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>1020021940</td>\n",
       "      <td>1020021940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4046600.5</td>\n",
       "      <td>4046600.5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>MULTIPOLYGON (((0.97778 5.9875, 0.97022 5.9884...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020027430</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>1020027430</td>\n",
       "      <td>1020027430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6923559.6</td>\n",
       "      <td>6923559.6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>MULTIPOLYGON (((23.28611 32.22083, 23.28133 32...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HYBAS_ID REGION_NAME  NEXT_DOWN   NEXT_SINK    MAIN_BAS  DIST_SINK  \\\n",
       "0  1020000010      Africa          0  1020000010  1020000010        0.0   \n",
       "1  1020011530      Africa          0  1020011530  1020011530        0.0   \n",
       "2  1020018110      Africa          0  1020018110  1020018110        0.0   \n",
       "3  1020021940      Africa          0  1020021940  1020021940        0.0   \n",
       "4  1020027430      Africa          0  1020027430  1020027430        0.0   \n",
       "\n",
       "   DIST_MAIN   SUB_AREA    UP_AREA  PFAF_ID  ENDO  COAST  ORDER  SORT  \\\n",
       "0        0.0  3258330.6  3258330.6       11     0      1      0     1   \n",
       "1        0.0  4660080.9  4660080.9       12     0      1      0     2   \n",
       "2        0.0  4900405.1  4900405.1       13     0      1      0     3   \n",
       "3        0.0  4046600.5  4046600.5       14     0      1      0     4   \n",
       "4        0.0  6923559.6  6923559.6       15     0      1      0     5   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((33.67778 27.62917, 33.67119 27...  \n",
       "1  MULTIPOLYGON (((34.80278 -19.81667, 34.79279 -...  \n",
       "2  MULTIPOLYGON (((5.64444 -1.47083, 5.62972 -1.4...  \n",
       "3  MULTIPOLYGON (((0.97778 5.9875, 0.97022 5.9884...  \n",
       "4  MULTIPOLYGON (((23.28611 32.22083, 23.28133 32...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the GeoDataFrames\n",
    "# https://geopandas.org/en/stable/docs/user_guide/mergingdata.html#appending\n",
    "hybas_all_lev02_gdf = pd.concat(gdf_list, ignore_index=True)\n",
    "hybas_all_lev02_gdf.REGION_NAME = hybas_all_lev02_gdf.REGION_NAME.astype('category')\n",
    "hybas_all_lev02_gdf.info()\n",
    "hybas_all_lev02_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to NGA TDX hydro directory\n",
    "tdx_proccessed_dir = tdx_dir / 'processed'\n",
    "tdx_proccessed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hybas_all_lev02_gdf.to_parquet(\n",
    "    tdx_proccessed_dir / 'tdx_regions.parquet',\n",
    "    compression='zstd',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TDX-Hydro GPKG files by HYBAS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
