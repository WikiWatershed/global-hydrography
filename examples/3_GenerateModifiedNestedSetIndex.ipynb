{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# Generate a Modified Nested Set Index from NGA TDX-Hydro\n",
    "\n",
    "This notebook demonstrates how to use functions in the [WikiWatershed/global-hydrography](https://github.com/WikiWatershed/global-hydrography) package to generate a modified nested set index using the TDX-Hydro datasets released by the [US National Geospatial-Intelligence Agency (NGA)](https://www.nga.mil).\n",
    "\n",
    "This example notebook assumes that you have already downloaded the applicable data using the example provided in the `1_GetData.ipynb` notebook. This notebook also assumes that you will have completed the necessary setup steps outline in the **[Installation Instructions](README.md#get-started)** (and also completed as part of the notebook `1_GetData.ipynb`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Imports\n",
    "\n",
    "In this step we will import the necessary python dependencies for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pyogrio\n",
    "\n",
    "from global_hydrography.delineation.mnsi import modified_nest_set_index\n",
    "from global_hydrography.preprocess import TDXPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile files that need to be processed\n",
    "\n",
    "In this step we will compile a list of the files that need to be processed to have a modified nested set index. Note this step assumes that you have downloaded the files to the same directory and used the same naming convention as the `1_GetData.ipynb` example notebook. If you have opted to use a different location or naming convention you will need to modify this step accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm your current working directory (cwd) and repo/project directory\n",
    "working_dir = Path.cwd()\n",
    "project_dir = working_dir.parent\n",
    "data_dir = project_dir / 'data_temp' # a temporary data directory that we .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan the files in the data directory and only pull of the streamnet (blueline) files\n",
    "files_to_process = []\n",
    "for item in data_dir.iterdir():\n",
    "    if item.is_file() and 'streamnet' in item.name:\n",
    "        files_to_process.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the modified nested set index\n",
    "\n",
    "In this step we will loop through each of the files to be processed, open them as a GeoDataFrame, applied the modified nested set algorithm, and then write them back to the original file. Note this steps assumes you have used the same file naming convention as the `1_GetData.ipynb` example notebook. If your naming convention is different, you may need to modify the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function for the operation\n",
    "def compute_mnsi(file:Path, preprocessor:TDXPreprocessor) -> None:\n",
    "\n",
    "    #parse the file name to get the HDX Basin Id\n",
    "    tdx_basin_id = int(re.search(\"\\d*\",file.name).group(0))\n",
    "\n",
    "    #open the file as GeoDataFrame\n",
    "    gdf = pyogrio.read_dataframe(file, use_arrow=True)\n",
    "    info = pyogrio.read_info(file)\n",
    "\n",
    "    #apply preprocessing to make linkno globally unique\n",
    "    gdf = preprocessor.tdx_to_global_linkno(gdf, tdx_basin_id)\n",
    "\n",
    "    #compute the modified nested set index\n",
    "    gdf = modified_nest_set_index(gdf)\n",
    "\n",
    "    #write back to the file\n",
    "    pyogrio.write_dataframe(gdf, file, layer=info['layer_name'], use_arrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a preprocessor instance\n",
    "#we want to reuse this object to take advantage of the cached TDX Basin Id crosswalk\n",
    "preprocessor = TDXPreprocessor()\n",
    "\n",
    "for file in files_to_process:\n",
    "    compute_mnsi(file, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
